# Solu√ß√£o de Dados em Tempo Real ‚Äì Squad de Pedidos

## üìå Objetivo
Desenhar uma arquitetura de dados em tempo real para apoiar a squad de pedidos na captura e an√°lise dos eventos transacionais gerados pela aplica√ß√£o de pedidos.

## üß© Vis√£o Geral da Solu√ß√£o

A solu√ß√£o proposta contem:
- Emiss√£o de eventos pela aplica√ß√£o de pedidos
- Ingest√£o em tempo real com Azure Event Hub
- Processamento cont√≠nuo com Databricks Structured Streaming
- Armazenamento no Delta Lake em tr√™s camadas (Bronze, Silver e Gold)
- Consumo dos dados via dashboards (Power BI), alertas (Azure Monitor) ou APIs

! [Diagrama da Solu√ß√£o](docs/Raquel_diagrama.pdf)

## üèóÔ∏è Arquitetura

### 1. Aplica√ß√£o de Pedidos
Respons√°vel por emitir eventos de pedidos via API no formato JSON.

### 2. Azure Event Hub
Servi√ßo de mensageria em tempo real que recebe os eventos da aplica√ß√£o. Alta escalabilidade e integra√ß√£o nativa com o Azure.

### 3. Azure Databricks ‚Äì Structured Streaming
L√™ os dados em tempo real do Event Hub, processa e armazena em Delta Lake.

### 4. Delta Lake
- *Bronze*: dados crus, vers√£o original dos eventos
- *Silver*: dados limpos, com normaliza√ß√µes e enriquecimentos
- *Gold*: dados prontos para consumo anal√≠tico

### 5. Camadas de Consumo
- Power BI (dashboards)
- Azure Monitor (notifica√ß√µes)
- APIs para integra√ß√µes

> ‚ö†Ô∏è Por se tratar de um case t√©cnico sem acesso ao ambiente real do Azure Databricks, a ingest√£o foi simulada com leitura de arquivos JSON em um diret√≥rio, eu criei uma pasta de input na minha m√°quina, salvei alguns arquivos .json com estrutura semelhante ao schema que coloquei no arquivo abaixo e copiei esses arquivos aos poucos para a pasta (testei com cerca de 40 segundos) para simular eventos chegando. Essa abordagem reproduz o comportamento de streaming com base na chegada de arquivos e permite testar a logica de transforma√ß√£o e escrita de dados de forma que seja minimamente parecida com o ambiente real ‚ö†Ô∏è

## üíª Exemplo de C√≥digo

Arquivo stream_ingestao_pedidos.py: exemplo de leitura do Event Hub e grava√ß√£o em Delta Lake com PySpark.

[.....](code/stream_ingestao_pedidos.py)

## üß© O que meu c√≥digo precisa fazer üß©
- *1*: *Conectar ao Event hub* (simulado)
- *2*: *Ler os dados em tempo real* (com Structured Streaming)
- *3*: *Converter os dados de JSON para colunas*
- *4*: *Gravar no delta lake* (camada bronze, dados raw)

## ‚öôÔ∏è Stack de Tecnologias

| Componente            | Tecnologia                | Justificativa |
|-----------------------|---------------------------|----------------|
| Ingest√£o de Eventos   | Azure Event Hub           | Escal√°vel, nativo do Azure |
| Processamento         | Databricks Structured Streaming (PySpark) | Integra√ß√£o com Event Hub e Delta Lake |
| Armazenamento         | Delta Lake (Bronze, Silver, Gold) | Governan√ßa e versionamento |
| Visualiza√ß√£o/Alertas  | Power BI, Azure Monitor   | Pronto para uso em real time |

## üë©‚Äçüíª Sobre mim

Case desenvolvido por Raquel Elias Zanatta Banuth para a vaga de Data Analytics Engineer 
